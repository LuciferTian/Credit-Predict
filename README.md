# Credit-Predict
## 目标 
根据客户个人信息为客户信用评分，预测该客户在向银行申请住房贷款时是否会违约。（数据挖掘课的作业，会构建一系列模型来进行预测）
## 数据采样
* 原始数据集中，违约客户和未违约客户分布严重失衡，数据采样时将违约客户当作负样本，采样所有的负样本，每一个负样本随机匹配一个正样本，
这是一个通常的采样方式，但是会破坏数据分布。为了更大限度地利用违约客户的信息，还是采取了这种方式

* 考虑时间效应的影响，选择客户不能选择最近一段时期的客户，因为无法从短期的记录来判断他是否会违约；不能选择太远时期的客户，避免经济政策环境
的影响。因此采样了三年前申请房贷的一些用户，截止时间在去年9月，这些客户有三年的观察期，最终的样本容量为1412*12
## 数据预处理
* 缺失值和异常值处理：只有月收入这个属性存在10个缺失值，占比不足1%，考虑用样本中位数进行填充；用箱线图判断异常点，发现有四个属性存在大量异常点，
考虑数据分布很偏，要谨慎处理异常值。提取四个属性中的异常样本做并集，做散点图，从散点图中判断极端异常值，去除极端异常值。为后续处理方便，将离散型属性放在左侧，连续型属性放在右侧，标签放在右侧最后一列，预处理后的数据存放在dataprocessing.csv中
## 构建模型
### 决策树
* 用scikit-learn中的决策树模型走过的坑：数据集中既有连续型属性也有离散型属性(有的是字符型的)，但scikit-learn只接受数值型数据，于是把所有字符型转为LabelEncoder编码，程序很快出了结果，precision跟recall也百分之九十多。把决策树可视化之后才发现不对，因为是二叉树，说明scikit-learn会把所有的数据当作连续值处理，这样的话，分类属性和连续属性没有差别，scikit-learn都是用二分法的方式。我当时觉得可能是因为编码的问题，因为LabelEncoder会把数据编码成1，2，3，4这样的整数，所以模型就会把这个分类属性当成是连续属性，于是换成OnehotEncoder，这种编码是做类似哑变量化的处理，可是也不对，可视化图出来还是二叉树，因为这种方法会把每一个分类属性都当作几个属性，可见这种编码方式只能增加树的深度，非常不适合树模型。于是，我枯了，多方查找资料，发现如下事实。

* scikit-learn中的决策树采用的是CART算法，这个算法只能做二叉树，criterion有两个：gini(基尼系数)是默认的，entropy(信息增益)是可选的，虽然有信息增益的选项，但还是只能生成二叉树。scikit-learn中没有诸如ID3、C4.5之类可以做多叉树的算法，只能手写代码。

* 数据集中有的分类属性是多个类别，必须做多叉树模型，于是我就只能手写了，当然我要站在巨人的肩上看风景啊，在网上找了看似不长的一份ID3算法写的决策树，改一改就出来了。presicion是0.93，recall是0.9，没有做剪枝，因为改完代码头晕，老师真是太为难我这个小菜鸡了。
