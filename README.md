# Credit-Predict
## 目标 
根据客户个人信息为客户信用评分，预测该客户在向银行申请住房贷款时是否会违约。（数据挖掘课的作业，会构建一系列模型来进行预测）
## 数据采样
* 原始数据集中，违约客户和未违约客户分布严重失衡，数据采样时将违约客户当作负样本，采样所有的负样本，每一个负样本随机匹配一个正样本，
这是一个通常的采样方式，但是会破坏数据分布。为了更大限度地利用违约客户的信息，还是采取了这种方式

* 考虑时间效应的影响，选择客户不能选择最近一段时期的客户，因为无法从短期的记录来判断他是否会违约；不能选择太远时期的客户，避免经济政策环境
的影响。因此采样了三年前申请房贷的一些用户，截止时间在去年9月，这些客户有三年的观察期，最终的样本容量为1412*12
## 数据预处理
* 缺失值和异常值处理：只有月收入这个属性存在10个缺失值，占比不足1%，考虑用样本中位数进行填充；用箱线图判断异常点，发现有四个属性存在大量异常点，
考虑数据分布很偏，要谨慎处理异常值。提取四个属性中的异常样本做并集，做散点图，从散点图中判断极端异常值，去除极端异常值。为后续处理方便，将离散型属性放在左侧，连续型属性放在右侧，标签放在右侧最后一列，预处理后的数据存放在dataprocessing.csv中
## 构建模型
### 决策树

* CART算法只能做二叉树。它对于连续属性会做跟C4.5算法一样的处理，但是对于离散属性，会递归地采取二分的方式选择最佳划分点；在C4.5中，离散属性节点会有所有的类别，但CART会根据划分点判断是否；在C4.5中已经出现过的离散属性不会再出现，但在CART中，它依然会出现。参数criterion有两个：gini(基尼指数)是默认的，entropy(信息增益)是可选的，虽然有信息增益的选项，但还是只能生成二叉树。scikit-learn中的决策树采用的是CART算法，只接受数值型数据，算法将所有属性都视为连续属性。这种递归二分的做法使得CART相比其他方法更快，适合大数据集。tree.png是可视化图像，节点不同颜色代表不同类别，越深代表越纯。

* ID3算法划分准则采取信息增益，对取值多的特征有偏好，且只能处理离散属性，不能处理连续属性；C4.5算法用信息增益率来修正ID3的偏好，对连续属性用二分法处理；C5.0所用内存更小，采用boosting方法多次迭代，在前一次的基础上学习，效果更好。但总的来说，CART既可做分类又可做回归，但节点只有二叉；其他几个算法只能做分类，其中ID3只接受离散属性。

* ID3.py是基于ID3的思想手写的决策树代码，连续属性做二分处理，presicion是0.9，recall是0.93；CART.py是用python中sklearn库的决策树函数做的，precision是0.96，recall是0.98；C50.R是调用R语言中做C5.0算法的包，precision是0.93，recall是0.98.


